{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927728b8",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **<span>Task 4: Image Segmentation Using Clustering Methods</span>**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import feature, filters\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a4685",
   "metadata": {},
   "source": [
    "# 1. Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fe095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_dataset(image_dir, annotation_path, num_images=50, scale_factor=8):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        all_annotations = json.load(f)\n",
    "\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    sampled_files = np.random.choice(image_files, min(num_images, len(image_files)), replace=False)\n",
    "    \n",
    "    images = []\n",
    "    annotations = []\n",
    "    \n",
    "    for img_file in sampled_files:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        height, width = img.shape[:2]\n",
    "        new_width = width // scale_factor\n",
    "        new_height = height // scale_factor\n",
    "        img_resized = cv2.resize(img, (new_width, new_height))\n",
    "        \n",
    "        images.append(img_resized)\n",
    "\n",
    "        img_id = os.path.splitext(img_file)[0]\n",
    "        if img_id in all_annotations:\n",
    "            annotations.append(all_annotations[img_id])\n",
    "        else:\n",
    "            annotations.append(None)\n",
    "    \n",
    "    return images, annotations\n",
    "\n",
    "images, annotations = load_and_preprocess_dataset('/Users/sarayetel/Desktop/UT/Data Science/DataScience/CA5&6/4_Image_Segmentation_Using_Clustering_Methods/data/images', '/Users/sarayetel/Desktop/UT/Data Science/DataScience/CA5&6/4_Image_Segmentation_Using_Clustering_Methods/data/annotations/instances_default.json')\n",
    "\n",
    "np.save(\"images.npy\", np.array(images, dtype=object))\n",
    "with open(\"annotations.json\", \"w\") as f:\n",
    "    json.dump(annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596346ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"images.npy\", allow_pickle=True)\n",
    "with open(\"annotations.json\", \"r\") as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48433873",
   "metadata": {},
   "source": [
    "# 2. Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7139f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(image, method='comprehensive'):\n",
    "    \"\"\"\n",
    "    Create advanced features for clustering with multiple feature types\n",
    "    \n",
    "    Parameters:\n",
    "    image: input image\n",
    "    method: feature creation method ('comprehensive', 'texture_rich', 'edge_aware')\n",
    "    \n",
    "    Returns:\n",
    "    features: feature matrix for clustering\n",
    "    \"\"\"\n",
    "    height, width, channels = image.shape\n",
    "    pixels = image.reshape(-1, channels) / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # Position features (always included)\n",
    "    x_coords = np.repeat(np.arange(width), height) / width\n",
    "    y_coords = np.tile(np.arange(height), width) / height\n",
    "    \n",
    "    if method == 'comprehensive':\n",
    "        # Color features\n",
    "        color_features = pixels\n",
    "        \n",
    "        # Texture features using Local Binary Patterns\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        lbp = feature.local_binary_pattern(gray, 8, 1, method='uniform')\n",
    "        lbp_features = lbp.reshape(-1, 1) / lbp.max()\n",
    "        \n",
    "        # Edge features using Sobel filters\n",
    "        sobel_x = filters.sobel_v(gray)\n",
    "        sobel_y = filters.sobel_h(gray)\n",
    "        edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        edge_magnitude = edge_magnitude.reshape(-1, 1) / edge_magnitude.max()\n",
    "        \n",
    "        # Concatenate all features\n",
    "        features = np.column_stack((color_features, x_coords, y_coords, \n",
    "                                   lbp_features, edge_magnitude))\n",
    "        \n",
    "    elif method == 'texture_rich':\n",
    "        # Color features\n",
    "        color_features = pixels\n",
    "        \n",
    "        # Multiple texture features\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Gabor filter responses\n",
    "        gabor_filters = []\n",
    "        for theta in np.arange(0, np.pi, np.pi/4):\n",
    "            for sigma in (1, 3):\n",
    "                for frequency in (0.05, 0.25):\n",
    "                    gabor = filters.gabor(gray, frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)[0]\n",
    "                    gabor_filters.append(gabor.reshape(-1, 1))\n",
    "        \n",
    "        # Local Binary Patterns\n",
    "        lbp = feature.local_binary_pattern(gray, 8, 1, method='uniform')\n",
    "        lbp_features = lbp.reshape(-1, 1) / lbp.max()\n",
    "        \n",
    "        # Concatenate all features\n",
    "        texture_features = np.column_stack(gabor_filters + [lbp_features])\n",
    "        features = np.column_stack((color_features, x_coords, y_coords, texture_features))\n",
    "        \n",
    "    elif method == 'edge_aware':\n",
    "        # Color features\n",
    "        color_features = pixels\n",
    "        \n",
    "        # Edge features with multiple methods\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Canny edges\n",
    "        canny_edges = feature.canny(gray, sigma=1).astype(float).reshape(-1, 1)\n",
    "        \n",
    "        # Sobel edges\n",
    "        sobel_x = filters.sobel_v(gray)\n",
    "        sobel_y = filters.sobel_h(gray)\n",
    "        sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2).reshape(-1, 1) / np.max(sobel_x**2 + sobel_y**2)\n",
    "        \n",
    "        # Laplacian edges\n",
    "        laplacian = filters.laplace(gray).reshape(-1, 1) / np.max(filters.laplace(gray))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        edge_features = np.column_stack([canny_edges, sobel_magnitude, laplacian])\n",
    "        features = np.column_stack((color_features, x_coords, y_coords, edge_features))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feature method: {method}\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cd568",
   "metadata": {},
   "source": [
    "# 3. Cluster Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a698e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Parameter Optimization Functions -----------------------------\n",
    "\n",
    "def find_optimal_k_elbow(features, k_range=range(2, 11), minibatch=True, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Find optimal k using elbow method\n",
    "    \"\"\"\n",
    "    if sample_size < len(features):\n",
    "        indices = np.random.choice(len(features), sample_size, replace=False)\n",
    "        sample_features = features[indices]\n",
    "    else:\n",
    "        sample_features = features\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(sample_features)\n",
    "    \n",
    "    inertias = []\n",
    "    for k in k_range:\n",
    "        if minibatch:\n",
    "            km = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=4096)\n",
    "        else:\n",
    "            km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(feats_scaled)\n",
    "        inertias.append(km.inertia_)\n",
    "    \n",
    "    # Calculate the elbow point (point of maximum curvature)\n",
    "    inertias = np.array(inertias)\n",
    "    differences = np.diff(inertias)\n",
    "    second_diff = np.diff(differences)\n",
    "    elbow_point = np.argmax(np.abs(second_diff)) + 2  # +2 because we lost two elements in diffs\n",
    "    \n",
    "    # Plot the elbow curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, inertias, 'bo-')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.axvline(x=k_range[elbow_point], color='r', linestyle='--', label=f'Elbow at k={k_range[elbow_point]}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return k_range[elbow_point]\n",
    "\n",
    "def find_optimal_k_silhouette(features, k_range=range(2, 11), minibatch=True, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Find optimal k using silhouette score\n",
    "    \"\"\"\n",
    "    if sample_size < len(features):\n",
    "        indices = np.random.choice(len(features), sample_size, replace=False)\n",
    "        sample_features = features[indices]\n",
    "    else:\n",
    "        sample_features = features\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(sample_features)\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    for k in k_range:\n",
    "        if minibatch:\n",
    "            km = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=4096)\n",
    "        else:\n",
    "            km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(feats_scaled)\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        if k > 1:  # Silhouette score requires at least 2 clusters\n",
    "            score = silhouette_score(feats_scaled, labels)\n",
    "            silhouette_scores.append(score)\n",
    "        else:\n",
    "            silhouette_scores.append(-1)  # Invalid for k=1\n",
    "    \n",
    "    optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "    \n",
    "    # Plot silhouette scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, silhouette_scores, 'bo-')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Method For Optimal k')\n",
    "    plt.axvline(x=optimal_k, color='r', linestyle='--', label=f'Optimal k={optimal_k}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return optimal_k\n",
    "\n",
    "def find_optimal_dbscan_params(features, eps_range=np.arange(0.1, 1.0, 0.1), \n",
    "                              min_samples_range=range(5, 50, 5), sample_size=5000):\n",
    "    \"\"\"\n",
    "    Find optimal DBSCAN parameters using silhouette score\n",
    "    \"\"\"\n",
    "    if sample_size < len(features):\n",
    "        indices = np.random.choice(len(features), sample_size, replace=False)\n",
    "        sample_features = features[indices]\n",
    "    else:\n",
    "        sample_features = features\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(sample_features)\n",
    "    \n",
    "    best_score = -1\n",
    "    best_eps = None\n",
    "    best_min_samples = None\n",
    "    \n",
    "    # Reduce dimensionality for DBSCAN to improve performance\n",
    "    pca = PCA(n_components=min(10, feats_scaled.shape[1]))\n",
    "    feats_reduced = pca.fit_transform(feats_scaled)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for eps in eps_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            db = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "            labels = db.fit_predict(feats_reduced)\n",
    "            \n",
    "            # Only calculate silhouette score if we have at least 2 clusters\n",
    "            unique_labels = np.unique(labels)\n",
    "            if len(unique_labels) > 1 and len(unique_labels) < sample_size/2:\n",
    "                score = silhouette_score(feats_reduced, labels)\n",
    "                results.append((eps, min_samples, score))\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_eps = eps\n",
    "                    best_min_samples = min_samples\n",
    "    \n",
    "    print(f\"Best DBSCAN parameters: eps={best_eps}, min_samples={best_min_samples}, score={best_score}\")\n",
    "    return best_eps, best_min_samples\n",
    "\n",
    "def find_optimal_agglomerative_params(features, n_clusters_range=range(2, 11), \n",
    "                                     linkage_types=['ward', 'complete', 'average', 'single'],\n",
    "                                     sample_size=5000):\n",
    "    \"\"\"\n",
    "    Find optimal Agglomerative clustering parameters using silhouette score\n",
    "    \"\"\"\n",
    "    if sample_size < len(features):\n",
    "        indices = np.random.choice(len(features), sample_size, replace=False)\n",
    "        sample_features = features[indices]\n",
    "    else:\n",
    "        sample_features = features\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(sample_features)\n",
    "    \n",
    "    best_score = -1\n",
    "    best_n_clusters = None\n",
    "    best_linkage = None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for n_clusters in n_clusters_range:\n",
    "        for linkage in linkage_types:\n",
    "            # Ward linkage can only be used with Euclidean distance\n",
    "            if linkage == 'ward':\n",
    "                agg = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "            else:\n",
    "                agg = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage, affinity='cosine')\n",
    "            \n",
    "            labels = agg.fit_predict(feats_scaled)\n",
    "            \n",
    "            # Calculate silhouette score\n",
    "            if n_clusters > 1:  # Silhouette score requires at least 2 clusters\n",
    "                score = silhouette_score(feats_scaled, labels)\n",
    "                results.append((n_clusters, linkage, score))\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_n_clusters = n_clusters\n",
    "                    best_linkage = linkage\n",
    "    \n",
    "    print(f\"Best Agglomerative parameters: n_clusters={best_n_clusters}, linkage={best_linkage}, score={best_score}\")\n",
    "    return best_n_clusters, best_linkage\n",
    "\n",
    "# ------------------------- Enhanced Clustering wrappers -----------------------------\n",
    "\n",
    "def run_kmeans_optimized(features, method='silhouette', minibatch=True, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Run KMeans with optimized parameters\n",
    "    \"\"\"\n",
    "    # Find optimal k\n",
    "    if method == 'silhouette':\n",
    "        n_clusters = find_optimal_k_silhouette(features, minibatch=minibatch, sample_size=sample_size)\n",
    "    else:  # elbow method\n",
    "        n_clusters = find_optimal_k_elbow(features, minibatch=minibatch, sample_size=sample_size)\n",
    "    \n",
    "    print(f\"Using k={n_clusters} for KMeans\")\n",
    "    \n",
    "    # Scaling important for mixing different feature types\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    if minibatch:\n",
    "        km = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=4096)\n",
    "    else:\n",
    "        km = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    \n",
    "    km.fit(feats_scaled)\n",
    "    labels = km.labels_\n",
    "    \n",
    "    # Calculate final silhouette score\n",
    "    if n_clusters > 1:\n",
    "        score = silhouette_score(feats_scaled, labels)\n",
    "        print(f\"Final Silhouette Score: {score}\")\n",
    "    \n",
    "    return labels, km, scaler, n_clusters\n",
    "\n",
    "def run_dbscan_optimized(features, sample_size=5000):\n",
    "    \"\"\"\n",
    "    Run DBSCAN with optimized parameters\n",
    "    \"\"\"\n",
    "    # Find optimal parameters\n",
    "    eps, min_samples = find_optimal_dbscan_params(features, sample_size=sample_size)\n",
    "    \n",
    "    print(f\"Using eps={eps}, min_samples={min_samples} for DBSCAN\")\n",
    "    \n",
    "    # Scaling important for mixing different feature types\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Reduce dimensionality for better performance\n",
    "    pca = PCA(n_components=min(10, feats_scaled.shape[1]))\n",
    "    feats_reduced = pca.fit_transform(feats_scaled)\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "    labels = db.fit_predict(feats_reduced)\n",
    "    \n",
    "    # Calculate silhouette score if possible\n",
    "    unique_labels = np.unique(labels)\n",
    "    if len(unique_labels) > 1 and len(unique_labels) < len(features)/2:\n",
    "        score = silhouette_score(feats_reduced, labels)\n",
    "        print(f\"Final Silhouette Score: {score}\")\n",
    "    \n",
    "    return labels, db, scaler, (eps, min_samples)\n",
    "\n",
    "def run_agglomerative_optimized(features, sample_size=5000):\n",
    "    \"\"\"\n",
    "    Run Agglomerative clustering with optimized parameters\n",
    "    \"\"\"\n",
    "    # Find optimal parameters\n",
    "    n_clusters, linkage = find_optimal_agglomerative_params(features, sample_size=sample_size)\n",
    "    \n",
    "    print(f\"Using n_clusters={n_clusters}, linkage={linkage} for Agglomerative Clustering\")\n",
    "    \n",
    "    # Scaling important for mixing different feature types\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    if linkage == 'ward':\n",
    "        agg = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "    else:\n",
    "        agg = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage, affinity='cosine')\n",
    "    \n",
    "    labels = agg.fit_predict(feats_scaled)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    if n_clusters > 1:\n",
    "        score = silhouette_score(feats_scaled, labels)\n",
    "        print(f\"Final Silhouette Score: {score}\")\n",
    "    \n",
    "    return labels, agg, scaler, (n_clusters, linkage)\n",
    "\n",
    "# ------------------------- Main clustering function -----------------------------\n",
    "\n",
    "def cluster_image_pixels(image, clustering_method='kmeans', feature_method='comprehensive', \n",
    "                        optimize_params=True, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Main function to cluster image pixels with optimized parameters\n",
    "    \n",
    "    Parameters:\n",
    "    image: input image\n",
    "    clustering_method: 'kmeans', 'dbscan', or 'agglomerative'\n",
    "    feature_method: 'comprehensive', 'texture_rich', or 'edge_aware'\n",
    "    optimize_params: whether to optimize parameters automatically\n",
    "    sample_size: sample size for parameter optimization\n",
    "    \n",
    "    Returns:\n",
    "    labels: cluster labels for each pixel\n",
    "    model: fitted clustering model\n",
    "    scaler: fitted scaler\n",
    "    params: parameters used for clustering\n",
    "    \"\"\"\n",
    "    # Create advanced features\n",
    "    print(\"Creating features...\")\n",
    "    features = create_advanced_features(image, method=feature_method)\n",
    "    \n",
    "    # Run clustering with optimized parameters\n",
    "    print(f\"Running {clustering_method} clustering...\")\n",
    "    \n",
    "    if clustering_method == 'kmeans':\n",
    "        if optimize_params:\n",
    "            labels, model, scaler, params = run_kmeans_optimized(\n",
    "                features, method='silhouette', sample_size=sample_size)\n",
    "        else:\n",
    "            labels, model, scaler = run_kmeans(features)\n",
    "            params = model.n_clusters\n",
    "            \n",
    "    elif clustering_method == 'dbscan':\n",
    "        if optimize_params:\n",
    "            labels, model, scaler, params = run_dbscan_optimized(\n",
    "                features, sample_size=sample_size)\n",
    "        else:\n",
    "            labels, model, scaler = run_dbscan(features)\n",
    "            params = (model.eps, model.min_samples)\n",
    "            \n",
    "    elif clustering_method == 'agglomerative':\n",
    "        if optimize_params:\n",
    "            labels, model, scaler, params = run_agglomerative_optimized(\n",
    "                features, sample_size=sample_size)\n",
    "        else:\n",
    "            labels, model, scaler = run_agglomerative(features)\n",
    "            params = (model.n_clusters, model.linkage)\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown clustering method: {clustering_method}\")\n",
    "    \n",
    "    return labels, model, scaler, params\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load an image (replace with your image loading code)\n",
    "    # image = cv2.imread('your_image.jpg')\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Example with a sample image (you'll need to replace this with your actual image)\n",
    "    # For demonstration, creating a dummy image\n",
    "    height, width = 100, 100\n",
    "    dummy_image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Cluster with optimized parameters\n",
    "    labels, model, scaler, params = cluster_image_pixels(\n",
    "        dummy_image, \n",
    "        clustering_method='kmeans', \n",
    "        feature_method='comprehensive',\n",
    "        optimize_params=True\n",
    "    )\n",
    "    \n",
    "    # Reshape labels to image dimensions\n",
    "    segmented_image = labels.reshape(height, width)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(dummy_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(segmented_image, cmap='viridis')\n",
    "    plt.title('Segmented Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4822ed00",
   "metadata": {},
   "source": [
    "# 4. Filtering and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_merge_clusters(segmented_img, min_size=50, max_size=5000):\n",
    "    \"\"\"\n",
    "    Filter and merge clusters based on size and proximity\n",
    "    \n",
    "    Parameters:\n",
    "    segmented_img: clustered image\n",
    "    min_size: minimum cluster size to keep\n",
    "    max_size: maximum cluster size to keep\n",
    "    \n",
    "    Returns:\n",
    "    filtered_img: image after filtering and merging\n",
    "    \"\"\"\n",
    "    # Label connected components\n",
    "    labeled_array, num_features = ndimage.label(segmented_img)\n",
    "    \n",
    "    # Calculate sizes of each component\n",
    "    component_sizes = np.bincount(labeled_array.ravel())\n",
    "    \n",
    "    # Create a mask for components that meet size criteria\n",
    "    size_mask = (component_sizes >= min_size) & (component_sizes <= max_size)\n",
    "    size_mask[0] = False  # Background component\n",
    "    \n",
    "    # Apply size filter\n",
    "    filtered_labels = np.zeros_like(labeled_array)\n",
    "    for label in range(1, num_features + 1):\n",
    "        if size_mask[label]:\n",
    "            filtered_labels[labeled_array == label] = label\n",
    "    \n",
    "    # Merge nearby clusters based on proximity\n",
    "    # This is a simplified approach - you might need a more sophisticated method\n",
    "    props = measure.regionprops(filtered_labels)\n",
    "    \n",
    "    # Create a new image with merged clusters\n",
    "    merged_img = np.zeros_like(filtered_labels)\n",
    "    current_label = 1\n",
    "    \n",
    "    for prop in props:\n",
    "        # Get bounding box of the region\n",
    "        min_row, min_col, max_row, max_col = prop.bbox\n",
    "        \n",
    "        # Check if this region is close to any existing region in merged_img\n",
    "        found_nearby = False\n",
    "        for existing_label in range(1, current_label):\n",
    "            existing_region = merged_img == existing_label\n",
    "            if np.any(existing_region):\n",
    "                # Check if regions are close (simplified distance check)\n",
    "                existing_props = measure.regionprops(existing_region.astype(int))\n",
    "                if existing_props:\n",
    "                    ex_min_row, ex_min_col, ex_max_row, ex_max_col = existing_props[0].bbox\n",
    "                    \n",
    "                    # Calculate distance between bounding boxes\n",
    "                    vertical_dist = max(0, max(min_row, ex_min_row) - min(max_row, ex_max_row))\n",
    "                    horizontal_dist = max(0, max(min_col, ex_min_col) - min(max_col, ex_max_col))\n",
    "                    \n",
    "                    if vertical_dist < 20 and horizontal_dist < 20:  # Threshold for merging\n",
    "                        merged_img[filtered_labels == prop.label] = existing_label\n",
    "                        found_nearby = True\n",
    "                        break\n",
    "        \n",
    "        if not found_nearby:\n",
    "            merged_img[filtered_labels == prop.label] = current_label\n",
    "            current_label += 1\n",
    "    \n",
    "    return merged_img\n",
    "\n",
    "# Usage example:\n",
    "# filtered_img = filter_and_merge_clusters(segmented_img, min_size=100, max_size=5000)\n",
    "# plt.imshow(filtered_img, cmap='nipy_spectral')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3171b1",
   "metadata": {},
   "source": [
    "# 5. Even More Clustering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_mask_and_centroids(filtered_img):\n",
    "    \"\"\"\n",
    "    Create binary mask and compute centroids of connected components\n",
    "    \n",
    "    Parameters:\n",
    "    filtered_img: filtered and merged cluster image\n",
    "    \n",
    "    Returns:\n",
    "    binary_mask: binary mask where 1 represents potential players\n",
    "    centroids: list of centroid coordinates for each component\n",
    "    \"\"\"\n",
    "    # Create binary mask (non-zero values become 1)\n",
    "    binary_mask = (filtered_img > 0).astype(np.uint8)\n",
    "    \n",
    "    # Find connected components\n",
    "    labeled_mask, num_features = ndimage.label(binary_mask)\n",
    "    \n",
    "    # Calculate centroids\n",
    "    centroids = []\n",
    "    props = measure.regionprops(labeled_mask)\n",
    "    \n",
    "    for prop in props:\n",
    "        centroids.append(prop.centroid)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(binary_mask, cmap='gray')\n",
    "    plt.title('Binary Mask')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(labeled_mask, cmap='nipy_spectral')\n",
    "    for centroid in centroids:\n",
    "        plt.plot(centroid[1], centroid[0], 'ro', markersize=5)\n",
    "    plt.title('Components with Centroids')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return binary_mask, centroids\n",
    "\n",
    "# Usage example:\n",
    "# binary_mask, centroids = create_binary_mask_and_centroids(filtered_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284f07a",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth_masks(annotations, image_shape):\n",
    "    \"\"\"\n",
    "    Load ground truth masks from annotations\n",
    "    \n",
    "    Parameters:\n",
    "    annotations: annotation data for an image\n",
    "    image_shape: shape of the image (height, width)\n",
    "    \n",
    "    Returns:\n",
    "    gt_mask: ground truth binary mask\n",
    "    \"\"\"\n",
    "    if annotations is None:\n",
    "        return np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    height, width = image_shape[:2]\n",
    "    gt_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Draw polygons for each player\n",
    "    for player in annotations.get('players', []):\n",
    "        if 'segmentation' in player and player['segmentation']:\n",
    "            # Convert polygon coordinates to image scale\n",
    "            polygon = np.array(player['segmentation']).reshape(-1, 2)\n",
    "            polygon[:, 0] = polygon[:, 0] * width / 1920  # Original width is 1920\n",
    "            polygon[:, 1] = polygon[:, 1] * height / 1080  # Original height is 1080\n",
    "            \n",
    "            # Draw filled polygon\n",
    "            polygon = polygon.astype(np.int32)\n",
    "            cv2.fillPoly(gt_mask, [polygon], 1)\n",
    "    \n",
    "    return gt_mask\n",
    "\n",
    "def calculate_iou(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two masks\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "def calculate_dice(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate Dice coefficient between two masks\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    \n",
    "    if (mask1.sum() + mask2.sum()) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return 2 * intersection / (mask1.sum() + mask2.sum())\n",
    "\n",
    "def evaluate_segmentation(images, annotations, pred_masks):\n",
    "    \"\"\"\n",
    "    Evaluate segmentation results against ground truth\n",
    "    \n",
    "    Parameters:\n",
    "    images: list of images\n",
    "    annotations: list of annotations\n",
    "    pred_masks: list of predicted binary masks\n",
    "    \n",
    "    Returns:\n",
    "    results: DataFrame with evaluation metrics for each image\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, (img, ann, pred_mask) in enumerate(zip(images, annotations, pred_masks)):\n",
    "        # Load ground truth mask\n",
    "        gt_mask = load_ground_truth_masks(ann, img.shape)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        iou = calculate_iou(pred_mask, gt_mask)\n",
    "        dice = calculate_dice(pred_mask, gt_mask)\n",
    "        \n",
    "        results.append({\n",
    "            'image_id': i,\n",
    "            'iou': iou,\n",
    "            'dice': dice\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Usage example:\n",
    "# Assuming we have images, annotations, and pred_masks from previous steps\n",
    "# results_df = evaluate_segmentation(images, annotations, pred_masks)\n",
    "# print(results_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d468f9",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373931be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_pipeline(image_dir, annotation_path, num_images=10):\n",
    "    \"\"\"\n",
    "    Complete segmentation pipeline\n",
    "    \"\"\"\n",
    "    # Step 1: Load and preprocess dataset\n",
    "    print(\"Step 1: Loading and preprocessing dataset...\")\n",
    "    images, annotations = load_and_preprocess_dataset(image_dir, annotation_path, num_images)\n",
    "    \n",
    "    # Step 2: Create features\n",
    "    print(\"Step 2: Creating features...\")\n",
    "    features = create_features(images, method='color_position')\n",
    "    \n",
    "    # Steps 3-5: Cluster, filter, and create binary masks\n",
    "    pred_masks = []\n",
    "    for i, (img, feat) in enumerate(zip(images, features)):\n",
    "        print(f\"Processing image {i+1}/{len(images)}\")\n",
    "        \n",
    "        # Step 3: Cluster pixels\n",
    "        labels = cluster_pixels(feat, method='kmeans', n_clusters=7)\n",
    "        segmented_img = labels.reshape(img.shape[0], img.shape[1])\n",
    "        \n",
    "        # Step 4: Filter and merge clusters\n",
    "        filtered_img = filter_and_merge_clusters(segmented_img, min_size=100, max_size=5000)\n",
    "        \n",
    "        # Step 5: Create binary mask and centroids\n",
    "        binary_mask, centroids = create_binary_mask_and_centroids(filtered_img)\n",
    "        pred_masks.append(binary_mask)\n",
    "    \n",
    "    # Step 7: Evaluation\n",
    "    print(\"Step 7: Evaluating results...\")\n",
    "    results_df = evaluate_segmentation(images, annotations, pred_masks)\n",
    "    \n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"Mean IoU: {results_df['iou'].mean():.4f}\")\n",
    "    print(f\"Mean Dice: {results_df['dice'].mean():.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Usage example:\n",
    "# results = complete_pipeline('path/to/images', 'path/to/annotations.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2b29e",
   "metadata": {},
   "source": [
    "Questions (short answers)\n",
    "\n",
    "\n",
    "1) Provide an example of a segmentation task where each type is appropriate:\n",
    "\n",
    "\n",
    "- Semantic segmentation: Satellite imagery land-use classification. Each pixel\n",
    "should be labeled 'water', 'forest', 'urban', etc. We don't care about\n",
    "individual instances of 'tree' or 'building' — only the class matters.\n",
    "\n",
    "\n",
    "- Instance segmentation: Autonomous driving pedestrian detection where you\n",
    "need to separate each pedestrian as a distinct instance (for counting and\n",
    "tracking). Here we need per-instance masks.\n",
    "\n",
    "\n",
    "- Panoptic segmentation: Robotic scene understanding in a cluttered indoor\n",
    "environment where you need both class labels for stuff (floor, wall) and\n",
    "individual instance IDs for things (mug, laptop). Panoptic combines both.\n",
    "\n",
    "\n",
    "2) Dice vs IoU:\n",
    "\n",
    "\n",
    "- Dice = 2 * (|A ∩ B|) / (|A| + |B|) and IoU = |A ∩ B| / |A ∪ B|.\n",
    "- Dice tends to be a bit more forgiving for small objects because of the\n",
    "2*intersection term; IoU penalizes false positives/negatives more strictly.\n",
    "- For unbalanced masks with small objects, Dice can show higher sensitivity.\n",
    "IoU is stricter and often preferred for segmentation benchmarks.\n",
    "\n",
    "\n",
    "3) Autoencoders for clustering images:\n",
    "\n",
    "\n",
    "- Autoencoders learn a compact latent representation of input images. Train\n",
    "an autoencoder on the image set; use the encoder's bottleneck outputs as\n",
    "fixed-length vectors for each image. Then apply clustering (e.g., KMeans)\n",
    "on these latents instead of raw pixels.\n",
    "- Advantages: lower dimensionality, noise suppression, features are learned\n",
    "to capture useful structure. This dramatically speeds up clustering and\n",
    "yields better cluster separation than clustering on raw pixels or high-dim\n",
    "vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
